{
  "os":  "Linux-3.10.0-1160.25.1.el7.x86_64-x86_64-with-glibc2.34",
  "python":  "3.12.5",
  "startedAt":  "2024-11-19T01:35:24.643438Z",
  "args":  [
    "--config-path",
    "conf",
    "--config-name",
    "prompt.yaml",
    "++train_config.enable_fsdp=false",
    "++train_config.enable_ddp=true",
    "++train_config.use_fp16=true",
    "hydra.run.dir=/home/liu.ten/demo/tmp/exp1-TinyLlama-1.1B-librispeech-linear-steplrwarmupkeep1e-4-wavlm-large-20241118",
    "++model_config.llm_name=TinyLlama-1.1B",
    "++model_config.llm_path=TinyLlama/TinyLlama-1.1B-Chat-v0.1",
    "++model_config.llm_dim=2048",
    "++model_config.encoder_name=wavlm",
    "++model_config.normalize=true",
    "++dataset_config.normalize=true",
    "++model_config.encoder_projector_ds_rate=5",
    "++model_config.encoder_path=/home/liu.ten/demo/SLAM-LLM/src/slam_llm/models/WavLM-Large.pt",
    "++model_config.encoder_dim=1024",
    "++model_config.encoder_projector=linear",
    "++dataset_config.dataset=speech_dataset",
    "++dataset_config.train_data_path=/home/liu.ten/demo/SLAM-LLM/examples/asr_librispeech/train_data.jsonl",
    "++dataset_config.val_data_path=/home/liu.ten/demo/SLAM-LLM/examples/asr_librispeech/validation_data.jsonl",
    "++dataset_config.use_data_augmentation=true",
    "++dataset_config.input_type=raw",
    "++log_config.use_wandb=true",
    "++log_config.wandb_exp_name=exp1",
    "++train_config.model_name=hate_speech_detection",
    "++train_config.use_data_augmentation=true",
    "++train_config.experiment_type=exp1",
    "++train_config.num_epochs=200",
    "++train_config.freeze_encoder=true",
    "++train_config.freeze_llm=true",
    "++train_config.batching_strategy=custom",
    "++train_config.warmup_steps=1000",
    "++train_config.total_steps=100000",
    "++train_config.lr=1e-4",
    "++train_config.validation_interval=100",
    "++train_config.batch_size_training=8",
    "++train_config.val_batch_size=5",
    "++train_config.num_workers_dataloader=2",
    "++train_config.output_dir=/home/liu.ten/demo/tmp/exp1-TinyLlama-1.1B-librispeech-linear-steplrwarmupkeep1e-4-wavlm-large-20241118",
    "++metric=acc"
  ],
  "program":  "/home/liu.ten/demo/SLAM-LLM/examples/asr_librispeech/finetune_asr.py",
  "codePath":  "SLAM-LLM/examples/asr_librispeech/finetune_asr.py",
  "git":  {
    "remote":  "https://github.com/Sirius1094/hate-speech-detection.git",
    "commit":  "abfba8e83a0a59629da7f2d7538f5eafd38672fe"
  },
  "email":  "arno.liut@gmail.com",
  "root":  "/home/liu.ten/demo/test_wandb",
  "host":  "d1019",
  "username":  "liu.ten",
  "executable":  "/home/liu.ten/miniconda3/bin/python",
  "codePathLocal":  "examples/asr_librispeech/finetune_asr.py",
  "cpu_count":  28,
  "cpu_count_logical":  28,
  "gpu":  "[]",
  "gpu_count":  1,
  "disk":  {
    "/":  {
      "total":  "16777216",
      "used":  "32768"
    }
  },
  "memory":  {
    "total":  "201178128384"
  },
  "cpu":  {
    "count":  28,
    "countLogical":  28
  },
  "gpu_nvidia":  [
    {
      "memoryTotal":  "34359738368",
      "cudaCores":  5120,
      "architecture":  "Volta"
    }
  ],
  "slurm":  {
    "cluster_name":  "(null)",
    "conf":  "/etc/slurm/slurm.conf",
    "cpus_on_node":  "2",
    "cpus_per_task":  "2",
    "export_env":  "NONE",
    "get_user_env":  "1",
    "gpus_on_node":  "1",
    "gtids":  "0",
    "job_account":  "cs5330.202510",
    "job_cpus_per_node":  "2",
    "job_end_time":  "1731998855",
    "job_gid":  "100",
    "job_gpus":  "0",
    "job_id":  "45164028",
    "job_name":  "sys/dashboard/sys/vscode",
    "job_nodelist":  "d1019",
    "job_num_nodes":  "1",
    "job_partition":  "gpu",
    "job_qos":  "normal",
    "job_start_time":  "1731977255",
    "job_uid":  "92895",
    "job_user":  "liu.ten",
    "jobid":  "45164028",
    "localid":  "0",
    "mem_per_node":  "4096",
    "nnodes":  "1",
    "nodeid":  "0",
    "nodelist":  "d1019",
    "prio_process":  "0",
    "procid":  "0",
    "script_context":  "prolog_task",
    "submit_dir":  "/var/www/ood/apps/sys/dashboard",
    "submit_host":  "infra-0a",
    "task_pid":  "62262",
    "tasks_per_node":  "1",
    "topology_addr":  "d1019",
    "topology_addr_pattern":  "node",
    "tres_per_task":  "cpu:2"
  },
  "cudaVersion":  "12.3"
}