2024-11-15 04:29:20,112 INFO    MainThread:9712 [wandb_setup.py:_flush():79] Current SDK version is 0.18.2
2024-11-15 04:29:20,112 INFO    MainThread:9712 [wandb_setup.py:_flush():79] Configure stats pid to 9712
2024-11-15 04:29:20,112 INFO    MainThread:9712 [wandb_setup.py:_flush():79] Loading settings from /home/liu.ten/.config/wandb/settings
2024-11-15 04:29:20,112 INFO    MainThread:9712 [wandb_setup.py:_flush():79] Loading settings from /home/liu.ten/demo/SLAM-LLM/wandb/settings
2024-11-15 04:29:20,112 INFO    MainThread:9712 [wandb_setup.py:_flush():79] Loading settings from environment variables: {}
2024-11-15 04:29:20,112 INFO    MainThread:9712 [wandb_setup.py:_flush():79] Applying setup settings: {'mode': None, '_disable_service': None}
2024-11-15 04:29:20,112 INFO    MainThread:9712 [wandb_setup.py:_flush():79] Inferring run settings from compute environment: {'program_relpath': 'SLAM-LLM/examples/asr_librispeech/finetune_asr.py', 'program_abspath': '/home/liu.ten/demo/SLAM-LLM/examples/asr_librispeech/finetune_asr.py', 'program': '/home/liu.ten/demo/SLAM-LLM/examples/asr_librispeech/finetune_asr.py'}
2024-11-15 04:29:20,112 INFO    MainThread:9712 [wandb_setup.py:_flush():79] Applying login settings: {}
2024-11-15 04:29:20,112 INFO    MainThread:9712 [wandb_init.py:_log_setup():532] Logging user logs to /home/liu.ten/demo/test_wandb/wandb/run-20241115_042920-5f1kcszo/logs/debug.log
2024-11-15 04:29:20,112 INFO    MainThread:9712 [wandb_init.py:_log_setup():533] Logging internal logs to /home/liu.ten/demo/test_wandb/wandb/run-20241115_042920-5f1kcszo/logs/debug-internal.log
2024-11-15 04:29:20,112 INFO    MainThread:9712 [wandb_init.py:init():616] calling init triggers
2024-11-15 04:29:20,113 INFO    MainThread:9712 [wandb_init.py:init():623] wandb.init called with sweep_config: {}
config: {'train_config': {'model_name': 'PATH/to/LLAMA/7B', 'enable_ddp': True, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'experiment_type': 'audio_only', 'batching_strategy': 'packing', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 3, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 1, 'use_data_augmentation': True, 'enable_gradient_checkpointing': False, 'use_peft': False, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'v_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': 'PATH/to/save/PEFT/model', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': False}, 'fsdp_config': {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': 'NO_SHARD', 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}, 'model_config': {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'TinyLlama-1.1B', 'llm_path': 'PATH/to/TinyLlama/1.1B', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'experiment_type': 'audio_only', 'input_type': 'raw', 'encoder_name': None, 'encoder_ds_rate': 2, 'encoder_path': None, 'encoder_dim': 1280, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': False, 'encoder_type': 'finetune'}, 'log_config': {'use_wandb': True, 'wandb_dir': '/home/liu.ten/demo/test_wandb', 'wandb_entity_name': 'arno-liut-northeastern-university', 'wandb_project_name': 'hate_speech_detection', 'wandb_exp_name': 'exp', 'log_file': '/home/liu.ten/test.log', 'log_interval': 5}, 'data_processing': {'augmentation': True}}
2024-11-15 04:29:20,113 INFO    MainThread:9712 [wandb_init.py:init():666] starting backend
2024-11-15 04:29:20,113 INFO    MainThread:9712 [wandb_init.py:init():670] sending inform_init request
2024-11-15 04:29:20,116 INFO    MainThread:9712 [backend.py:_multiprocessing_setup():104] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2024-11-15 04:29:20,117 INFO    MainThread:9712 [wandb_init.py:init():683] backend started and connected
2024-11-15 04:29:20,124 INFO    MainThread:9712 [wandb_init.py:init():778] updated telemetry
2024-11-15 04:29:20,140 INFO    MainThread:9712 [wandb_init.py:init():811] communicating run to backend with 90.0 second timeout
2024-11-15 04:29:20,289 INFO    MainThread:9712 [wandb_init.py:init():862] starting run threads in backend
2024-11-15 04:29:20,505 INFO    MainThread:9712 [wandb_run.py:_console_start():2464] atexit reg
2024-11-15 04:29:20,505 INFO    MainThread:9712 [wandb_run.py:_redirect():2312] redirect: wrap_raw
2024-11-15 04:29:20,506 INFO    MainThread:9712 [wandb_run.py:_redirect():2377] Wrapping output streams.
2024-11-15 04:29:20,506 INFO    MainThread:9712 [wandb_run.py:_redirect():2402] Redirects installed.
2024-11-15 04:29:20,509 INFO    MainThread:9712 [wandb_init.py:init():906] run started, returning control to user process
2024-11-15 04:29:20,903 WARNING MsgRouterThr:9712 [router.py:message_loop():77] message_loop has been closed
