Error executing job with overrides: ['++train_config.enable_fsdp=false', '++train_config.enable_ddp=true', '++train_config.use_fp16=true']
Traceback (most recent call last):
  File "/home/liu.ten/demo/SLAM-LLM/examples/asr_librispeech/finetune_asr.py", line 46, in main_hydra
    train(kwargs)
  File "/home/liu.ten/demo/SLAM-LLM/src/slam_llm/pipeline/finetune.py", line 172, in main
    model, tokenizer = model_factory(train_config, model_config, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "examples/asr_librispeech/model/slam_model_asr.py", line 18, in model_factory
    tokenizer = setup_tokenizer(train_config, model_config, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/liu.ten/demo/SLAM-LLM/src/slam_llm/models/slam_model.py", line 63, in setup_tokenizer
    tokenizer = AutoTokenizer.from_pretrained(model_config.llm_path)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/liu.ten/demo/transformers/src/transformers/models/auto/tokenization_auto.py", line 718, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/liu.ten/demo/transformers/src/transformers/models/auto/tokenization_auto.py", line 550, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/liu.ten/demo/transformers/src/transformers/utils/hub.py", line 430, in cached_file
    resolved_file = hf_hub_download(
                    ^^^^^^^^^^^^^^^^
  File "/home/liu.ten/miniconda3/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py", line 101, in inner_f
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/liu.ten/miniconda3/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
    validate_repo_id(arg_value)
  File "/home/liu.ten/miniconda3/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
    raise HFValidationError(
huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'PATH/to/TinyLlama/1.1B'. Use `repo_type` argument if needed.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
